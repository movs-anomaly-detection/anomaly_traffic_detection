# EDA

Был проведен разведочный анализ данных. Из изначальных json файлов выделили несколько колонок: 'addr', 'handshake', 'packets', 'port', 'proto', причем в колонках 'handshake', 'packets' также хранится важная информация, которую необходимо распарсить. В первую очередь распарсили самое важное: timestamps в handshake (их количество, а также медианную и среднюю дельту между ними), и, кроме того, выделили страну из ip адреса. Согласно нашему исследованию, именно эти данные сейчас часто используют для решения таких задач.

После EDA сделали первый подход к обучения простой модели машинного обучения - катбуста. Выяснили, что модель переобучилась под наши данные, убрали фичи, которые влияли на переобучение и сделали второй подход. Качество значительно упало, но теперь можем говорить о том, что модель не переобучена, а просто нуждается в доработке.

## Итерация 1

Использовали 7 фичей: 'addr', 'port', 'proto', 'num_timestamps', 'mean_timestamps', 'median_timestamps', 'country', причем в качестве категориальных фичей в катбуст передали следующие: 'addr', 'port', 'proto', 'country'.

Качество на тесте получили 0.94 и проверили важность фичей. Оказалось, что наиболее важны для модели 'addr', 'port' и все наши сгенерированные таймстемп-фичи. Посмотрели на порт, и оказалось, что в неаномальных данных присутствует только 443 порт, и он же, в части случаев присутствует в аномальных. В случае наличия аномалий на 443 порте модель ошиблась в 50% случаев, что говорит о том, что высокое качество было достигнуто просто за счет нестандартных портов, а на стандартных модель сильно ошибается. Удалили порт из наших данных.

Также посмотрели на адрес. Выяснили, что модель смотрит в тот адрес, который чаще всего встречался в наших аномальных данных, но не встречался в неаномальных вообще. Мы удалили строки с этим адресом, а саму колонку айпи адреса разбили на две, оставив от ip адреса только первые две цифры. И уже с этими фичами перешли ко второй итерации.

## Итерация 2

Использовали 7 фичей: 'proto', 'num_timestamps', 'mean_timestamps',  'median_timestamps', 'country', 'addr_1', 'addr_2'. Обучили тот же катбуст. Качество драматически упало: roc_auc_score теперь составляет 0.67 (было 0.94), f1_score - 0.48 (было 0.93). Наиболее важны для нашей моедли оказались сгенерированные таймстемпы из рукопожатий.

# Итог

Получили датафрейм с 7 признаками: 'proto', 'num_timestamps', 'mean_timestamps', 'median_timestamps', 'country', 'addr_1', 'addr_2', из них 'num_timestamps', 'mean_timestamps', 'median_timestamps' - количественные (взяты из блока рукопожатий); 'country', 'addr_1', 'addr_2', 'proto' - качественные, причем первые три из них сгенерированы с помощью ip адреса.

Цель последующей работы - дотянуть roc_auc_score до 0.9. Что будем делать:
1. Генерировать и тестировать новые фичи
  1.1. Возможно, сравним результат также с другой моделью
2. Обучим нейронную сеть
